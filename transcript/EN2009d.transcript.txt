yeah. so this was that face to face meeting. um but it uh it doesn't there isn't th so there are things in the eye tracker record that we definitely don't want in the g_d_f_ format, um like the frame rate eye movement. you know, we we uh uh i we're if we're expecting the g_d_f_ format to be um sort of a parsed version of events. and you know there's just too much raw frame f frame rate stuff coming out of this. you wouldn't prob you wouldn't want it in this kind of format for up-translation to the other things. yeah, we yeah, you can get back to it. yeah. we're not throwing anything away. this is just the stuff yeah. yeah. but the th but the way to think of this is this is the data that we want to be able to analyse against the other tracks of data. so the data that we wanna compare with a language or with whatever. and um so yeah. s so in essence what you would then do is well we're not doing frame rate at any frame for well, maybe we are. i don't know. i i had thought we were yeah, the eye tracker does. but but right. w what w um the kinds of events that we had r uh before talked about putting into the record for then use in elan and n_x_t_ isn't based on saying every x_ seconds something. you know, give me give me what's happening every x_ seconds. it's more like, you know, give me the fixations and the um the blinks. yeah. oh yeah. durations are in there. but it's not there's a difference between um saying that something is in a particular state every frame, whatever the frame rate is, you know, ten seconds a minute. you know, that's that's one kind of w way of looking at data, and um a parsed version of the data, which isn't at um any particular length. it relies on this really close frame rate that's underneath. no, no. the time the time is still in there. but you'll get uh what you want is to figure out what are the um the concepts behind that data that you want represented. so rather than saying the eye was at this particular place, you know, here, and then a tenth of a second later here and then a tenth of a second later here. you say there was a fixation from this time to that time and there was blink from this time to that time. and okay. mm-hmm. right. so there's two issues here. we're not throwing anything away. but the question is what tool would you use to get that information out of the data? would you be so the more you can plan mm-hmm. yeah. mm-hmm. so you need to know the percentage of time it was on during that fixation. yeah? okay, so the percentage is i i is a cut it's not something you're using for measurement. it's a cut-off for whether or not it counts as a fixation? is that mm-hmm. mm-hmm. mm-hmm. right. yeah. 'cause all you wanna know is whether they were looking at the same object in the period after. yeah. okay. can we draw it to make sure that that um that this is satisfying ellen's concerns? well, there's a white-board, right. we love this thing. see if the pens work. so um this is um a_'s eyes, right? and b_'s eyes. and i think what you're saying you should probably draw this right, is that they you know, if um from this time to this time they're looking at triangle one. w what you're saying is that you want to know in the critical you wanna know after they're they're looking at triangle one what's happening in this period with this guy, right? mm-hmm. mm-hmm. mm-hmm. mm-hmm. mm-hmm. mm-hmm. yeah. so mm-hmm. alright. so yeah. so, you know, he might get triangle one there and no maybe this one's gonna overlook lap quite a bit. so what you want to do is be able to define um bigger periods, which is the period when they're sort of interested in triangle one overall, right? this is sort of some meta level analysis. yeah. but that's that's not a something that you can do in the n_x_t_ query language, but it you can't do that in any you know, this is such special purpose s but it's easy enough given the data format for any of these things to do that. so you could do it on 'cause i it's just a matter of i the hard part is deciding how close together these have to be before you decide that this is a event that you wanna pull out. because, you know, algorithmically you're you're already putting together i mean this is essentially already, you know, these fixations with stuff in between. and uh um, you know, we we've got an algorithm for deciding when that's a look, i guess. you already have that or no? oh yeah, yeah. so it's all fixations. they're these are all fixations and saccades, but within the yep. so that's easy enough. so the hard thing is they could be moving their eye arbitrarily here, right? and you know, maybe even having fixations on other things? yeah? yep. back and forward. yep. so um this isn't yeah. but what you need to do is we we can already build into this g_d_f_ format these regions if you can give a definition of what you think that is. but i think the right way to do this is to be able to inspect the data in um some tool and play around with the definitions. because you won't get it right the first time. yeah. mm-hmm. and uh elan's a reasonable choice for that, right? what you need is something well no, because you need to y you need to be able to see the effects of this. so i g i guess this is a case of craig writing some scripts so robin having some ideas about what the relationship is and saying, you know, add this data a automatically. it i mean it's not that hard, right. it's just there'll be a bunch of these, you'll have some rules about how maybe how long you spend on other objects and w whether the other object is um the existing construction or not, right. and so um ah, right. so if they if they uh they had a fixation on c_ you wouldn't be worried. but if they had a fixation on yeah, they're yep. but yeah, they're gonna look at the clock um and they're gonna look at they may look at completely irrelevant mm-hmm. yeah. but that's like a separate analysis, right. so it no no. the so every separate yeah. mm-hmm. yeah. but what we find e what we can get out of the data easily at the moment is at this kind of level, right. and then it's a case of defining algorithmically all these other transformations that you want. so this is one uh we hadn't thought of adding before, but we should, right. which is um well, how would you decide whether something was the current addendum uh the cu so that's a human decision. yeah. um but the ex but we believe but we believe j_p_ to be defining that maybe. yeah. mm-hmm. i could believe them, yeah, no, taking an interest in that. i mean the general division was language here and other stuff there, right. i'll just i'll just minute that. oh yeah, eye tracker here. yeah, i mean we know that. well yeah. but i mean with transaction coding on something like this you would use i y you wouldn't consider it verbal analysis exactly. it'd be verbal plus action. because it's a task breakdown. it's just a segmentation. yeah, but you wouldn't have you you wouldn't do two codings for task level one you wouldn't do transaction coding in a action segmentation. i i don't think that's realistic, because i think what you'd actually do is use um the full record of what you have and do a segmentation. i think it'd be hard to understand what was going on if you used like just the language without watching the video to decide whether we're breaking down the task. oh, you don't want it to be coding th uh based on that though and then that seems a strange way to go about things. i mean this the language events are multi-modal, right. you know, they're they're doing all these things together. wha why do you care whether they can do it just based on the the language? is well, it seems to me much less important than the other things one could get out of this data. but i, you know, i it's a possibility. we'll yeah, well i c i can see maybe wanting to know whether you can do the chunking just based on the actions without the language in cases where they use both. it's more g i can't quite see why it's important to know that they can do it just based on the language when w you know that they had both. uh-huh. well, i think that one's just bound to fail. but yeah. really? okay. anyway. so back back to this main problem, which is yeah, w the record that we are getting in the first instance is about the m about these you know, they're looking at some region of the screen defined dynamically. and then we need some way of knowing what the you can you can see adding these other analyses about, you know, they're they're jointly focused on this region and trying to figure out what s percentage of time they're looking at it as adding new tiers of information to either the elan track or n_x_t_. they're they're both sort of track based in this way. um but the hard part is knowing how you wanna do that. and i i think in the first instance what we're trying to get into the g_d_f_ format is just this. and then we've got no option but to uh figure out a way for like to look at this, just explore this data, suggest ways about doing it and um be able to play them back and see um when we think we've got these things right. i don't think we even know what the set of these things are that we want, much less how to get 'em yet. so th yeah, that's right. so this is not the you know, this is something we're aiming for. but this isn't something that affects what craig programs for the initial g_d_f_ translation. um yeah. so let's just return to this question of frame rate. because this is the thing we were not planning to um transfer into this format. so again, you know, what a frame rate kind kind of coding is ag it can again be seen as a track. but it says it's a coding like this, right, where you say it's in state a_, state b_, state c_, state a_. right. so you right. so i'm just you're happy that it's not gonna have frame rate uh like this. it's gonna have an interpretation like this. what does that mean? sorry. right. w right. but it seems to me it seems to me that ellen's concerns might mean we need to add more information to these tags because um, you know, this thing in itself is th bunch of fixations, right, with saccades. fixations and the percentage of time those fixations cover, you might want. okay. so number of fixations. percentage of no no. this is this is still um uh summary data. they're he's we're talking about just adding attributes to these things that say the number of fixations that counted as that looking at triangle one, right. so y it's possible yeah, the spots'll be different anyway. 'cause i you're not gonna g have the same pixel. so um we have the option that we can put in an a_ fixation thing here, right, as well. if you want the smaller if you want the smaller coding in in here. so that it's not just parsed into this idea of which object. but you also have the raw fixation um data. we can put that in as another track. if you think that that's something that you might want to look at in one of these tools that shows you the tracks against each other. yeah, i d that's all he asked for. yeah. well, i think yeah, and in n_x_t_ there's no cost, right, because the y the uh you just don't choose to load those. all we're doing is dumping it as output that you can load if you choose to. um i g s you know, so if they're things that you just know are crazy and you're not gonna want then we don't do it. but otherwise we go ahead and dump 'em. 'cause it's easy to dump out the fixations. um yeah? okay. so it's the number of fixations the did you want the you m not e well, if it's each, you have to d you have to break it down into another tier, right. you can't you can say there were three fixations and they averaged uh a certain time. but you don't wanna d well, what about the the overall sum of the durations? is that i mean which way do you want to yeah, then that's that's the way you want it? that way around? okay. and uh y did you want the percentage of time fixated as opposed to which is sort of another view of this number. you can have as many of these as yeah. well, it's not um the the extra cost of having these as attributes is not high. so um, you know, it saves you i uh having to do write scripts to do arithmetic on that later if you know that these are numbers that are gonna be useful to you. mm-hmm. yeah. i don't know. well well but y those are different tracks of information. so what you want is one track of information about which object it's one, one about whether or not it's on the other guy's gaze, and one about whether it's on um one of the mouse positions. yeah, but i in in the analysis you should treat those as completely separate tracks of information. because they can be looking at they could look sim simultaneously at somebody's mouse, somebody's gaze and some object, right. so yeah. so the these are independent. so so what we want is whether they're looking at s at the other person's gaze, right, and say they are in this period well, i mean uh they're probably not given what i've trying to mm-hmm. mm-hmm. mm-hmm. yeah. so g so there's there's a lot of tracks here, right. because well we just added this fixation track. and then there is a_'s mouse, not their eyes, is on an object, right. and the mouse might be on triangle one. but it doesn't matter. i mean i the mouse we're just saying where is the mouse. you know, it's on this object. and then um a_'s eye is on well a_'s mouse i guess, right. a_'s eye might be looking at a_'s mouse here. a_'s eye might be looking at b_'s mouse here, right. i mean these are all the different ways of taking cross-products at the things that could be co-located. so you just treat 'em as independent. and i'm guessing from what you say yeah. i guessing from what you're saying you want all these tracks. yeah, which is fine. there's no problem with that at all. yeah. s so um uh you kinda got the idea here? yeah. but the important thing is you don't treat that entire set as mutually exclusive and exhaustive. it's just so tha the objects is like a separate level of analysis. if whether they're looking at the objects than whether they're looking at the gaze. 'cause they can happen at the same time. does that happen? oh, right. uh-huh. okay. so what you're saying is like a new problem for us, which is i'm gonna change that's the bad one. yeah. so you're saying okay. can you write on my pen pad? just say, yeah, pens. white-board pens. so you're saying, you know, they could be looking at um uh square one at this point. 'cause they close together. okay, that's a problem for the data models and either of the things that we were using. what do you mean by greatest overlap? draw uh my g my uh spacial reasoning is no good. see uh i i'm the one that uses the white-board. 'cause i actually put the the microphones on. uh this is the better pen. uh-huh. yeah. but you had a way of choosing which one, right? so you just mean which i is it closer to the is the circle i mean, what is this circle? they're looking at a pixel or something, right? right. s right. oh, so those vary in size. yeah yeah. mm-hmm. yeah. they could be. oh, but what pain that's gonna be analytically. because it's gonna how many parts are there? like okay. i know ways of getting around this analytically. 'cause you c if they're really close to each other, it's gonna get foxed. yeah. it's not the data format i'm worried about. it's the um the way you do the analysis. because you don't wanna have to say um, you know, did they jointly look at triangle one. okay. did they jointly look at square one. okay. did they jointly look at you know, you need some way of uh uh going over the whole thing. but i c we can find ways around that. i think for now we we do it this way and then we we think about what we need out of it in the end. it's just you know, in elan it that has the side effect that if you go for the naturalistic way of of up-translating to elan, there'll be a zillion tracks. and it'll probably ruin their viewer. 'cause you'll get very sparse data on each track. it'll be like the old referring expression generalis uh uh visualization um the map task. you know, where they talk about one object one landmark and then another landmark. well, it's big, right. well we'll see if elan likes it or not. yeah, and we b we better also like have in the representational list of par like even in the n_x_t_ up-translation a list of parts. it it affects the way we do the n_x_t_ u up-translation and make things easier for people. well the and it suddenly becomes and there could be more than one construct at a time, right. it's there is no the construct, right. what why does it why does construct one become construct two when you add something to it? yeah. oh, and this is because we don't want it to stay triangle one when you start with a construct it's not a construct at all, it's just a one thing. and we don't want triangle one to suddenly have bigger stuff. yeah yeah, there are. there are. mm-hmm. yeah. that was the next question i had. yeah. oh yeah. mm-hmm. that'll cover most of 'em. mm-hmm. i yeah. it's triangle two. you don't because that's you'd have to have human coding to do that. yeah, there might be multiple triangles that you've broke and you won't know which one they're planning on using it for. well you know which mold they come from. and so you know which shape they match. but you can't possibly know which one of the ones they're meant to replace. oh, so there's no two parts with the same shape? then oh same shape and colour. right okay. oh okay. so you can tell what it's meant to replace then. because it's the same it's uh just a case of the mold, right? yep. yeah. but the this also mm-hmm. mm-hmm. yeah. we in when you specify these things, do you specify the molds or does it figure out what the molds are based on? so is this hard-wired into tim's program? or is it just an artifact of the way we s right. okay. so it's hard-wired. so minor modification needed for mm-hmm. uh but what were the req wha has multiples, yeah. mm-hmm. mm. yeah, uh but they don't have enough to make unique mm-hmm. so what yeah. mm-hmm. so i th i think we've gotten to the point where, you know, to try to summarise, uh we we think tim's program can do both of these conditions that you want. but i'm still worried about what the uh effects are for analysis. because you were aiming at something in um the g_d_f_ format and i wasn't quite sure what. and w yeah. so so okay. so i'll summarise what we said about that part that um every time you cast off a new part from a mold or, you know, every black triangle has a different i_d_. and you know it's a black triangle 'cause you know which mold it came from. but you don't know which part it was intended to replace on the screen, because you can't mind-read. what do you mean define? mm-hmm. mm. i think that this is a human coding that is part of the action coding. because i don't see how anybody but a person watching this can guess why they cast off this thing at this time. yeah, but that's okay 'cause they all have different underlying part numbers. and when you say what a construct no. no, no. yes. mm-hmm. yeah. so we can easily look at things like that automatically. it's just the why they g why they get new parts that's the problem for us. we can't if they suddenly if they decide to get a part of a mold we don't know we can't know why until they do something with it, if they do. oh yeah, you said that. um yeah, but you can but you can break you you can but you can break one when you break one, you don't cast off the mold yourself, it happens automatically? oh okay, never mind then. so they just have to use it, yeah. uh-huh. oh, but they have to drag it up past the mold line. yeah. mm-hmm. yeah, where there's extra parts. yeah. okay. so this why question doesn't even arise because 'cause you know what they're gonna do with it. when they decide to move it past the mold line, they're p doing something with it probably and you'll know what they're gonna do with it because they do it. yeah. how would you do that? yeah, but there's there'd be no way of coding that automatically, right. how could you possibly do that? but that's a human coding, right. mm-hmm. so w so uh that's gonna particularly be a problem for j_p_, right. remember m all the things we're looking at are f with language with and without language. and it's gonna be very difficult to tell whether they broke something intentionally without the language. which means it's probably not yeah, okay. but th um this is properly part of the action coding. so we should well we should make a wish list, right, as a side effect. mm. they could discuss deciding to break something and and then one guy does it. yeah, yeah. mm-hmm. no, no. it was them just dr uh forgetting to um define an attribute they had to well, whi which is probably a documentation fault, right. yeah. yeah. is there a y yeah. well, while we're on past things, is there anything else you wanna tell us about the prior part of this, which is the, you know, what else is he holding you up from uh-huh. right. so it doesn't slow down the eye tracker. it doesn't do anything nasty. so we we p so we pay for it and nothing important and noth nothing big enough they're gonna look at it, right? yep. yeah. yeah, yeah. i know. oh, do you need two copies of camtasia to do that? so you're gonna look into this, right? well y c look at the licence conditions, it might not i c i never pre-judge licences until i've read 'em. so uh well and um hold on, before we get go any further. so this has implications for data storage, right? because w um it means we've got well no, this is three times, right, 'cause we've got oh no, we're gonna build we're gonna use javascript to build the videos on the fly, right, 'cause it's fast. so the the permanent storage is just the camtasia stuff. so uh is that a problem? where are we putting things? oh we can we can put 'em in the same thing, right? you can dump 'em into one video frame if you don't mind losing resolution. but that's maybe a problem, right, because so the synchronization's gonna be a problem. yeah, before the task. no. so these are ba these are back-ups. right. so the flash get allows you to hand-synchronize them later if you need to by stripping extra video off the front. as long as you make sure you start 'em before the flash then you're fine. but it will there's a a cost of having to go to back-up, which is synchronizing them. oh okay. so you so you should start the camtasia really early then. right. okay. uh-huh. that's not where you're putting it. i mean u well okay, you've got the proper sound record. but you're not dumping it through camtasia to record it, right. you're what before we were gonna use camtasia at all, what well what we were gonna do what were we going to do with the sound? uh-huh. so uh ha wou is there any sound degradation that comes about from putting this through camtasia rather than running it out straight? okay. so what you're planning on doing it is bunging it on one of the camtasia tracks and then splicing it off the camtasia track. it's an easy bit of yeah. and then you're gonna bung it on the other camtasia track too if you need it, right? but we'll just we're gonna store all three separately then. and the sound is going to start at the same time as one of that arbitrary one of the camtasia videos. but you'll know when the real experiment you'll know the relationship between that and the eye tracker timings? yeah. no human intervention required. it's time-stamped. yeah. but ho hold on. do we need that? i mean it i i thought the way that tim had this set up originally, um the audio uh w the time stamps used there would be joint time stamps between the audio and the eye tracker, so that, you know, uh the audio record ten seconds in was the same as ten seconds into the eye tracker record so that we didn't have to do any extra hand work, you know, any uh chopping the starts of audio signals to get there was nothing okay. so we're relying on your matlab script to get us the chopped version of the audio, right? right, so we can either adjust the eye trai track data or we can actually chop the audio signal to take off the first whatever, however many seconds. yeah, but uh but d um the uh lining up the camtasia two is gonna take we w he's working on a matlab script for the sound but not for so the one that's got the sound on it, that'll also tell you where to chop the video to get it to line up. the one that doesn't have the sound on it, it won't. oh. so it's just got the bleeps. oh okay, so w no hand synchronization required at all. um as long as the scripts work, right. 'kay. how confident are you about the finding these things? so we just have to w hope we don't have an any subjects with the odd vocalizations. yeah. okay. yeah. 'cause this this is the drop-out test. yep. okay. yeah, yeah. mm. oh yeah. i know but so you g you got a solution for that then? oh right, okay. yeah. you're sure there's not a better solution that involves 'cause, you know, people might wanna use this for speech recognition or something. you never know if it's the data is there then you know. yeah. and you're gonna want forced alignment. oh no. well no no. better to collect and sort. uh well it's the mono wait wait, w i i thought the sol that a better solution was fixing this problem with the mono microphone socket. sound card? so you said the problem was the m it the m m i is expecting a mono microphone input. so is that fixable? like is there any way yeah. uh i think a new sound card sounds a better solution than monkeying about with trying to filter white noise out. which isn't hard. but hi but it's only got one input, right. i believe it's easy to put two monos into a stereo signal. yeah. so yeah, yeah. so is there any reason why we wou don't do that? yeah. well, it's in the old days we probably would have want a little if they'd been in the same room we would have had a little stereo thing in the background as backup as well just to make sure. 'cause it's slightly dicier you know, if his scripts don't work then you don't get the overlap. it doesn't have to be a real trial. it just has to be two guys talking in the two bits. and then we've both been so badly bitten in the past. yeah. but this this sounds reasonable to me. i so i think yeah. do do they both have the same sound card problem? i wouldn't count on it. okay. oh well uh yeah. i think tell the guys. to yeah, yeah. yeah. mm-hmm. yeah, it's just the way they wired it. so um it's getting late and i've got a two o'clock and i've got a nice lunch. so i wanna eat my lunch today. uh what did you wanna get through today more? i mean i think i think it was useful going through your expectations about this. 'cause um that's quite a bit clearer in my head at least and but i think mostly we leave you to go away and re-design the g_d_f_ or add new bits to the g_d_f_ along these lines. and then w yeah, yeah, yeah. but i think the thing to do is um for you to go away and think about it this way with the different tracks for the different objects and the um the kinds of things we've added about whether they're looking at the other person's gaze and what have you, and and try to change the spec so it it reflects this and maybe um oh maybe by that point there will be some sample data or something uh and the right thing to do is for us to look at the sp the spec the way you understand it now and some data. and then ellen'll have new ideas about what's needed or about these post-analyses, you know, the and then and we can add 'em in. but it's gonna emerge over time. i mean that's clear. oh, so the spec to the other conversation, yeah. yeah, that's that's solved now. yeah, test. we have to test. well you don't have your models, or do you? yeah. yeah. well, uh anything you actually need fixed. you know. joe doesn't live here anymore, right? so well, i but he wasn't gonna be booking any time to us after the thirty first of october. so um that that means that any bugs that need fixed are now craig's responsibility, right? you don't know have any change on that, right? 'cause he that's what he said to us originally. so i would assume, you know, no more contact with joe. it's not fair to get work out of somebody for free. so you know, ask craig instead. yeah. i don't think well w he wasn't paid in advance. he's being paid in arrears. so it doesn't matter. uh i think it's i think it's better to have all the software. i mean it's not big things, it's just maintenance at this program at this point and yeah. i if he can give it, you know, like because the problem is you gotta have an immediately when you discover a bug in that. and we can make craig shift all his other priorities to do this 'cause we bought him. right. yeah. so it's a kinder way. it yeah. yeah. but it sounds like you don't think there's anything that actually needs fixed at the moment. because w we only need this to work well enough that you can use it for something and you got work rats. so and how many models do you need to completion? and how long does that take? and you got and you know about complexity? you're waiting on marloes. you can cold call her today, this afternoon. mm-hmm. that's her job. come on. oh yeah. okay. so you can dash in there for half an hour at a time? doesn't sound very useful for you. uh-huh. okay, well. you guys sort it out. mm-hmm. right, but it would be kind to tell her ahead of time which of your morning sessions you're bumped. yeah. mm-hmm. i thought that was the problem that your mornings weren't sliced off on the booking system. 'cause you know, i if you're sa told use the booking system yeah. and what are the instr what are the people upstairs downstairs have um i you know, as rules about who you hand the keys to. 'cause, you know, we like people to know to ground the oh i thought the the lending for the booking system caroline. see, 'cause you're supposed to uh have training in oh okay, so that's the safety. and you control those accounts. oh okay, that's fair enough. okay. uh-huh, yeah. that's safer. 'cause then they learn the first time. yeah, yeah. okay. i really have to get out of here. so um what else is important before you run? nothing, right? you got uh willing heads. oh, i don't think i brought my diary up. uh but maybe. why? okay. so yeah. mm-hmm. hmm. so do you know what time of day you might want? 'cause i should c i should check that. okay. you all have to b you'll have to be there to when it falls over. yeah. okay. so that all sounds f good fun. well i can just leave you guys here, you know. why not.
which data. you know, i i want everything and then i'll decide what i want. okay. we can get back to it. we can get we can always get back to it. we're not th actually throwing anything away. and if we decide to re-jig this at some finer mecha method. we'll still have the original and a method of uh of filtering. so mm-hmm. mm-hmm. mm-hmm. mm-hmm. okay. as long as the format in which we pick it up is a format which could be generalised to a finer take. because the worst thing that can ever happen to you is you discover that you've done huge amounts of analysis and th you actually had the data but you threw it away because you treated it so grossly. okay. so whatever we should be able to b you know, backtrack and say okay instead of every second, every tenth of a second or some such thing. but you know th well, the eye tracker does. mm-hmm. well, you need well one needs to know the duration of these things, right. so one needs to be able to say mm-hmm. mm-hmm. well so there's no real time, there's only ev there's only events. what i'm we're trying to figure out is whether we've thrown time away. here okay, so one of the formats in which eye tracker data is analysed is percentage of time spent on some target as opposed to some competitor over the first second after some event, okay. so you actually have to be shu have to show at some time slice rate whether the eye was on the same target as the other guy, a similar target, what we'd both been deali you know. so we have to b we have all the parts, the interesting parts of the screen identified and be able to show distribution of gaze over time. alright. now we could be really unlucky and somebody would expect us to do that at the real frame rate. but i think that's really unlucky. but but my point is that we mustn't throw away in or lose the capacity of being able to deliver that kind of data. mm-hmm. mm. s so typically the eye will move, right. so over any one second, they eye's actually f fixing on a bunch of different things. and you and so when you say the eye was on this from here to here what's gonna happen is that is that if you use the real frame rate, it's gonna jiggle all over the place. it's gonna be on this landmark. uh it's on this object, that object, this fixed thing, that fixed thing, okay. you're gonna get lots and lots of stuff. and it's percentage distribution that you're going to want. it's not uh i went here. i s you know, it's not like person walking. i went here, i stayed here. it's it's more like a fly hovering. mm-hmm. because if you if you take them as separate events you get thousands of separate events. mm-hmm. against bigger frames. well, that's the that's the problem. there are two ways of doing it. one is that there's always a cut-off, right. but the other is that there will be a time span, a kind of reaction to some event span. right. right. and so i mean there are there are really two ways of looking at this. one would like to know for example the percentage of time overall in which two people are looking at the same thing, okay. and one would like to know sequences of they didn't look at the same thing and then they broke it. or they did look at the same thing and then they did or didn't brea you know. one one could imagine those two categories. that's that's a kind of testing of our hypotheses. but there's a certain amount of um dues you pay to the way they do things in the literature to get your papers published. and one of the things they will want to know is an event series after some critical event, right. what percentage of time is given to looking where the other guy is looking. and what percentage of time over some, you know, reasonable time span of a couple of seconds, alright. so they'll be they they'll want to see essentially the gaze settling on particular incidents on particular places. so we have to be able to deliver those two things and they're rather different demands. right. or how l alright. let's let's imagine a typical construction event, okay. there is some part there are there are separate movable parts on the screen ready for use, right. there may be or not a construction already begun, right. somebody makes the first move. there's some kind of communication either gestural, imaginary or verbal, that plans how we're gonna do it, right. before that happens the person who speaks is going to do some kind of visual scanning. while they're speaking or communicating in some way, the other person may or may not be looking where they're looking, okay. they may be overlapping gaze at particular objects which are of interest. let's call it the c the construct, existing construct, which could be zero. alright. or the um the addendum, the thing which is next going to be added. next piece, okay. now in neither case, when you draw this, he's looking at triangle one, which you're actually drawing, you know, for a the period of time in which he's steadily looking at triangle one is gonna be very very short, right. because staring fixedly without interruption, blink or or saccade is is an extremely short event. that's fine. so it's in a region it's in a region. okay. but even so you're likely to get bouncing in and out of the region, right. so even so you wanna look at if we're interested in how long before the construction move takes place, um how much of the time they spend looking at the same thing. let's call that our measure of alignment. so they're gonna be yeah, that's right, a_ is gonna be on triangle one and various other places. that's right. and and b_ um okay. and we're gonna look at the percentage of of that time where they're both in the same region. right. so what i want to make sure is that we don't um simplify, do you know what i mean? temporarily simplify too much, so that yeah. 'cause then you lose percentage as an as a as a d_v_. right. and so b_ has some periods of looking at one and all it will which will also be intermittent. because right. mm-hmm. when they should be. right. okay. mm-hmm. well it right. what yes. yes, because for example for part of that time both b_ and a_ are probably looking at the construct, okay. if if your intention is to move the red triangle to sit on top of the thing already constructed, you would tend to look back and forth. right. and we should be able to to figure that out. yeah, sure. so so the question would be under what tool should we be looking at these events. so right. so so essentially there's there's um a_e_ is divided into t_r_ one and c_ and other stuff, okay, where c_ is the construct, the existing thing. well no. i mean we'd take a separate we'd look at the percentage time i mean i have no idea because i don't know how people look when they're building things together, okay. so there's a there's the addendum and the and the co the existing construct. and i don't know whether they're gonna spend more time looking at one or the other. but if they're whatever it is that one is looking at, if the other's looking the same place they're in good shape. yeah. sure, sure. and that's what the other stuff that's what the that's what the diagonal stripes are for. that's true. but we c we can one of the things we'll be doing is um categorising people i take it or interactions by the amount of time people spend looking at the clock. we'd expect that if we put people under time pressure they'll look at the clock a lot more. sure, it's a separate analysis. but you don't wanna throw it away, right. so so you can define if all of these things are actually categorised by the eye tracker as to where the eye is, alright, you should be able to pull out any interesting category and say alright for this phase it's t_r_ one, or c_. for this phase it's um s_q_ one or c_, okay. mm-hmm. mm-hmm. you have to actually transcribe the thing or watch the film further on. yeah. yeah, absolutely. yeah. right. right. yeah, that's the addendum in the construct should be, you know, kind of they they change their true identity. but they're i their categories of stuff now i w my kind of assumption was that that this was j_p_ land, that that's what he was re what he was really interested in was the kind of coding which would define the building sequence, okay? so and the and maybe he wants to think about that more and say well there were several candidates for the addendum, alright. and and it was the negotiation of which candidate was gonna be the right candidate that's actually the interesting stuff. so i should talk to him about this. he's he's actually um emailed me with a l with a list of things he wants to discuss at length. so i w i'll bring this one back to him. well this is my question for him. is he gonna define this kind of building sequence in a way that we can get out. or is he so b i mean, you know, they've been working on construction there for a while. so it may be that they have a coding system that's ready to go and we should just apply it. okay. um they do a lot of sub-assembly in the tasks they've been doing. so they may well have a yeah. let's find out. right. right. so wha right. what well we but we have the now actions i mean actions might mostly be theirs, right. but since we have the the eye tracker i th we're gonna have to answer their questions about gaze, right. yeah, i right. but um so they'll they'll uh they'll tell us something about that. but um presumably what you piously hope is happens here is what happened with um transactions, right, that the verbal analysis and the um and the visual analysis give you the same breaking points, the same chunking points. well, i mean what you know. it's it is it is a task breakdown. but for the verbal version there are ways of announcing that now we're doing a new one, right. or that we're finished with the old one. no, you wouldn't. but i mean one of the things one of the things you'd like to establish you know, as an as an outcome of this is that you could analyse either end and you'd get the same chunking of the material. the thing which you guys thought to make in a paper. it's a hypothesis. well they are doing these things together. but one of the things that you one could imagine doing is um sen is, you know, having the transcription there and pl just play it back to a bunch of captive undergraduates and say when do they stop and start um because because essentially you're looking at um cycling sequences in discourse. and if the discourse tells you what's going on that's information. i mean i g one of the questions is how the information is gonna be shared across these media. and if you can get it all out of the speech, you know, if the if all of the chunking is available when there is speech, okay, then it's carrying a lot of the burden. it's saying we are done with that and mm. but this is but we haven't looked at data like this with this with our old-fashioned analyses um, you know. and i it's it would be really nice to know that that much information, that chunking of the task information is being carried by the language. because j_p_'s question, the overriding question is so what's language for. you know, if people are busy interacting all the time and all of our colleagues don't even bother to control for whether people are talking to one another when they're doing these joint tasks because it seems to them to be irrelevant 'cause language is irrelevant, it would actually be nice to demonstrate that in a place where we're controlling whether you have language or not. you could get the entire chunking of the task out of a language. mm-hmm. mm-hmm. mm-hmm. because you know it's a self-contained system as opposed to a system which is which can't be interpreted without the other system. okay. usually the claim. almost all studies on language claim that language is a self-contained system which will give you everything you need to know. that's the claim. alright. i didn't say it was true. i said that's the claim. and so it's worth testing. mm-hmm. mm-hmm. mm-hmm. no no. and we won't and establishing the full set will, you know, take us much of the project. so you know fine. my only concern w uh you a as i said when i barged in was just to make sure that we didn't lose the things that we might need to pick up later. that's all. every single frame. well okay. but since the l the definitions of look a thing we're looking at are d um are the ones which get rid of the lower level. like jiggling around in the area of a particular object, right. so if we're moving the the green triangle um we've defined a region which is the dynamically the green triangle, wherever it is. we will jiggle around in there. but it doesn't matter where we are in there. that's beneath our level of analysis. s well the in that interpretation is definable to frame rate by our by the only way we're gonna use frame rate. i c well, i mean i because i can i can say for how many frames this fixation went is officially defined. so that as long as i as long as it's not a untimed event, okay. a and an end time. so it's, you know, it's fine. i can say it's a long one. or it's a short one. or it's, you know, it's twenty milliseconds more than that one. that's mm-hmm. mm-hmm. and okay, i'm i'm asking you as an expert. this is this this isn't a leading question. this is a question question. why would that be informative particularly? uh-huh. mm-hmm. uh-huh. on it. so you think that if for example if they're looking at um one or another um apex of a triangle it would just that would make a difference. they were exploring the thing, as opposed to they were simply alright, there is it there it is. okay, so th um so that really means that we're not throwing away absolute fixations. the screen location of absolute fixations. alright. uh-huh. as opposed to out of it. so you so i thought i understood you to mean exploring the figure. because you know, your fixation is a point. and the figures are bigger than points. so you could be exploring the figure or you could be just somewhere in the region defined as the figure but not on it. okay. alright, fine. the so you just want to know the variability of the of the fixation. and wouldn't that differ from person to person? okay. so it's the number of different spots within that region where the eye has fixed the number of different fix oh, ok okay. so it's a jiggle rate, okay. right. mm-hmm. well, all i th understood you to ask for was the duration of each fixation inside. yeah. you can come back. okay. right. so it's the number of different fixations. well, actually do you want the average duration? or do you want the number of different ones? duration of each fixation in the region. well, you've already got that. so that's a measure of jiggle in the region, roughly. moving. okay. what's our error of measurement on location on the screen? so to what degree do we actually know whether the two little eyes, little circles, are exactly in the same place or just somewhere in the same region? right, okay. right. mm-hmm. it's yeah, okay, right. s okay. so my question was going to be alright, the the mouse is a dynamic object, right. the eye track is a dynamic object? or is it only the the piece that the eye tra the other person's eye track is on that's that's an object in this definition? is a is an object. okay. with some with plus or minus something or other, yeah, around it. some circular area. okay. and um so you can be on the object but not on the other person's gaze. so there can be a triangle which has a_'s gaze in the centre and your gaze actually happens to be here. you're in the triangle region. does this okay. but it's directly added when when these two in this situation when these two overlap, right, like this. mm-hmm. mm-hmm. mm-hmm. mm-hmm. mm-hmm. well it would come up it would say yes, right? i mean because they would be in the same place. so if you y you're gonna have dynamic regions which overlap one another by definition. if the mouse is on the construct, then right, right. right. we treat those as as other objects. but the difference between them and the the parts of the c thing to be constructed is that they're allowed to overlap with other things so nothing breaks. okay? if we mm-hmm. ye mm-hmm. yes, as opposed to simply looking at somebody's gaze when the mouse isn't also there, right. and you want to know those things. right, they're i they're independent dynamic objects. okay. so a definition of we're all looking at and touching the same thing. so imagine that we've just added a piece to the construct, alright. so now that's the construct. and both mouse symbols are on it, right. and both gazes are on it, right. so at that point you should have a line-up of a_ is on the construct, a_ is on the mouse, a_ is on a_ is on a_'s mouse, a_ is on b_'s mouse, a_ is on b_'s gaze, and b_ likewise. okay. right. ooh, i love the eraser. mm-hmm. yeah, but the mouse is also a dynamic object. that's fine. okay. mm-hmm. mm. mm-hmm. right. and then you then you look for combinations of them. yeah. i think we need to. because tha some measure of alignment is looking where the other guy is directing attention. and there are two measures of where the other guy is directing attention that you get from the visual track. one is where the mouse is and the other is where the gaze is. so mm-hmm. right. right. so yeah, that actually true. be 'cause right, but that it's also gonna be the case that um whatever region you define as the region of the dynamic object of the red triangle may get to the point where it overlaps the region of the dynamic object of the green square. okay, what do we do about that? yeah, because if you have them close together, there's always some fuzz factor around them. and so if they're left lying close together, okay, or in the in fact in the model, in the not in the model, in the in the supplies set they're actually neatly packed into a little space. mm-hmm. mm-hmm. squeak squeak. yes. because the two are so close together that their regions overlap. mm-hmm. the greatest overlap with what? ho ho. i think i think you're throwing information away. yeah. but it may be a bad idea. it may be a bad idea. you've just thrown data away. yeah. j well the gaze will wobble. the gaze will wobble. that's natural. mm-hmm. or indeed they might be looking from one to another. d or deciding which one to choose or thinking so you don't want to decide it's only one and throw the other one out. mm-hmm. okay, well that's fine. that i was going to say that's the obvious way to do it. well each one is yes or no. couple of dozen. right. six to a dozen usually. mm-hmm. yeah. i mean i think it's very likely that um if people are considering f mm-hmm. well, not if the regions overlap, okay. if the regions i right. and if you define the regions so neatly that there's that, you know, that we're losing gaze because of jiggle outside this closely defined region when it's in the middle of space, then i mean i i actually like the solution, however ugly it it looks in terms of a data format of having a track for every possible object of gaze. mm-hmm. s a thing. mm-hmm. well okay. so mm-hmm. uh-huh. mm-hmm. mm-hmm. i always thought that was brilliant. yeah, it is big, and you do have to scroll through it to see what's going on. but it gives you a very clear picture of what's going on. yeah, well, okay. but so we'd we'd better do a test one and and listen to them scream. with parts. right. so i mean so mm-hmm. okay. so what about the point where a part becomes the construct? do you still identify it as a part? i mean i think one should lose that i take it. 'cause mm-hmm. mm-hmm. right. so you cha so every time a part is added to the construct, it becomes a new part. so the construct actually um has say it has six things that are added to some initial thing, okay. so if there's just the initial thing you've put it in the middle of the screen, that's just the initial object, right. soon as you put a part, there's a construct. but it's construct one. because when you add another part, construct one ceases to exist and you get construct two, right. so actually defining all of those as the construct is gonna be the trickiest thing. right. so you're you're looking at triangle one, right, and all of a sudden it ceases to exist. 'cause you can build sub-assemblies. and then you can start again. also when you when you screw it up, you g start again. because the definition mm-hmm. well, the problem is that all of these things are popping out of existence. so do we know the difference between um we broke it and it went away and um it's now part of the construct? can we ta can we tag the constructs with what's in them? yeah. okay. so we could we could essentially well, then we could cumulati or it is a new construct 'cause it has a new list of a new cumulative list of parts, right. but we will right. so so some fancy programming's gonna have to be done to say i was looking at triangle one and now i'm looking at triangle one in construct one. 'cause the first construct was triangle one and square one, okay. alright. so now we have to ask whether um so l let's imagine this, we've made a construct of two parts, and we're c i a triangle and a square. and we're considering now adding something on to the side of the square that isn't attached to the triangle. okay. are we looking at the square or we looking at the construct? yeah. uh in this definit should be looking at the construct. there isn't a way to figure out that you're looking at the square rather than the triangle. mm-hmm. it is. well okay, because i mean that's that's the example m f presumably that's the best example of overlapping overlapping areas. 'cause if if the thing the two s the two things are now abutted. of course there's an area which is common to both of them, okay. um so what i'm trying to run through in my head is that we can always tell the difference between um something going out of existence 'cause it's joined to construct something going out of existence 'cause we threw it away, right. suppose we pick up an we we we screwed up the first time we put the triangle with the square and we threw it away and decided we didn't like it, and we took another one. is it triangle one? is it triangle one prime or something like that? it's the replacement for triangle one. mm-hmm. well how do i know what it replaces? n n uh this is true. but if i have triangles one two three, right, and i throw them away, any triangles i take out are to replace one two three. okay. except that ex no, you don't know which one they're meant to replace. but you know they're not meant to replace any that are all that are that haven't been thrown away. okay. right. so the new parts are replacing those which have disappeared from the screen. and if there's no more t_r_ one track the t_r_ one track is gone now. oh there are many. same identity. oh, is that true? you've decided not to make all the triangles red and squares green and oh, okay. right. one two and three. they okay. so so there so shape plus colour. okay. they're unique. all the parts are unique. so wai hang on. that makes the task a little bit easier, right. the uh all the lines. so indeed. which kind of leaves you with an obvious way of making the same task harder and easier, doesn't it? but but that's hard to code. i mean that's really a thing we might do. okay. so now let's make sure that the coding would survive that. it's just it's a beautifully controlled situation. the construction task is essentially the same. it's the figuring out stuff that gets harder if everything is purple. for a just to choose a colour at random here. mm-hmm. mm-hmm. mm-hmm. so if you have five black triangles, there gonna be five black triangles in the parts box? or one? uh-huh. mm-hmm. mm-hmm. mm-hmm. mm-hmm. okay. as long as it this is possible. so c that that just is a kind of thing which is so simple, so much like a single one zero variable change that it if it that doesn't already exist. 'cause i'm tr i'm trying to kinda map this onto baufix. um and baufix has has multiple, you know, all the the the the v the nuts are are red or and all the um flat things are wood colour something. the same part the same part is different colours. oh yeah? so when you say a red nut or a green bolt or a long green bolt then there'll be lots of them lying around. and i think that's how the robot is set up to there are five five green bolts. uh here is one, you know. okay. okay. so okay, so w uh all i'm i'm doing is kind of worrying out loud about all the things that will happen that we'll miss by th a simple view of for example regions and looking at at triangle one. when is triangle one not triangle one anymore. um does it s keep its identity. mm. identity, yes. mm-hmm. that's true. so how can we define the shapes that people build? well if assuming i was for a moment i was j_p_ and i wanted to know how they actually went about building the thing. okay. and i wanted to um to look at the strategy. and i wanted to see if the strategy was different when we could talk about it and when we just picked up whatever. i mean suppose i can't talk to you and i'm doing this task with you and i can't talk to you. um the thing which is gonna be hardest for me is making elaborate plans with you. i can reach for the next thing and you can go where i reach. but if i have some, you know, sub-goal, some long-term sub-goal, of doing something clever with putting these together 'cause it's hard and then putting these together 'cause it's hard, there it's gonna be almost impossible to convey that to you. and the difference in the history of construction, right, is an important thing, and i wonder how we can get that information back. do you think? no, it why is not uh that's that's not the question i'm asking. the question i'm asking is what's the history of the construct? so you have the n the names of the things in there. and you have two constructs suppose we have two sub-constructs. and whichever one had two pieces put together first is the earlier numbered of those constructs, right. how do you tell the difference between adding a piece to this first construct and creating a second construct? mm. okay. it's it's it's parent child relationship. okay. so construct two could b um construct one is um a red triangle and a green square. construct two is um two green squares, okay. construct three, right, is a red triangle, a green square and another red triangle. construct four okay. okay. and you can so how are we gonna tell when for example you think we're gonna have to do human coding on when two sub-constructs are put together. no, that's a definition wherein a construct has a c has constructs as children? okay. okay. right. so we could zip we could zip through this and look at all the um all the interactions in which people build sub-construct contstructs first which we expect them to do bu as a wild hypothesis more when they have verbal communication than when they don't, okay. and we can do that by simply searching for any constructs that have constructs as children. okay. mm-hmm. yeah, we haven't actually made a rule that you can't uh collect extra parts, right? no no. i mean you have to b you have to break one to get one, okay. and you can't just bring extras in case you screw up. you have to screw up first and then you can bring an extra. mm-hmm. mm-hmm. mm. mm-hmm. i but it does have replacement. mm-hmm. mm-hmm. there there's a so you so so you appreciate you appreciate the cost of screwing up. mm-hmm.. mm-hmm, that's right. right. okay. so they rejected something or they broke something inadvertantly. okay. is there a way of telling the difference between intentional and unintentional breakages? bec yeah. no, you p they both put they both put their hands on a construct because they don't like it.. mm-hmm. yep. so that just has to be coded. mm-hmm. um not generically. because they'll if they're gonna do it by gesture they'll build up a convention, right. what else do we need to know? unless they develop a convention. suppose they start off with language and then they they say hey look, you know, let's do it like this. sure. absolutely. i just i just wanna make sure that a wish list, yes. yes. for sure you know that's and l or well n is not necessarily intentional. they could just screw up. yep. mm-hmm. or i don't think that's very good, no, we'll never get away with that, we'll get a bad score. let's just throw that away and start again, yeah. okay. which reminds we have fixed the score problem. have we? right. was the percentage overlap and that made the score? yeah? that's when i left. oh yeah, well do you know which which which which one was the top right. yeah. mm-hmm. but that's all been fixed. that's that's that's back. don't tell me it was a feature. alright. oh okay. oh. so hmm. but the right. not prominently flagged. okay. a communication flaw. okay. so we can now that's now just lovely. and there won't be any crazy scores anymore. oh. i have to use a new page. alright. so the last i think i'm sorry, you know, i had as assorted emails from you and i was probably didn't catch everything. the problem was that there are two camtasia records. they don't see their own gaze. they see the o only the other guy's gaze, right. huh huh. okay. i mean check out okay. so we mm-hmm. is there mm. is there such a thing um as um, you know, dual track video? because you can certainly mix things. um what ideally one wants one doesn't really want to l to have these things. uh um because we're using them for back-up and for coding. we don't really want to play them independently. we do almost always want to use them in exactly in parallel. time aligned. um what are we doing for synchronization otherwise? okay. so that we'd have to re-align them. we couldn't dump them from their start points. well, maybe you could. the thing that you're dumping them onto just starts running with the flash and the bleep. you turn on the two copies whenever at different times. but they're still no? is the what what i th what are they i don't really understand the the parts that are operating here. two videos are turning on. there is no time stamp that comes from some common source. mm-hmm. right. right. okay. right, is there a div mm. mm-hmm. mm-hmm. mm-hmm. so they'll include things like the um the eye tracker calibration, right, which is not a bad thing actually. because sometimes you wanna go back and find out if this was just a particularly duff subject.. right. yeah. and hand every time we re-calibrated the damn thing slipped, yeah. that actually helps. i mean that ni right. yep. mm-hmm. right. no, they that actually saves you hours trying to make somebody's data smooth out when it won't. because yeah. that's a technical term. that's a a technical categorization in psychological research. and that's because? well we need sound we we need real sound recording, right. that's that's two track. that's stereo. alright. uh-huh. on w on what? uh sorry. uh on one of the con o o it's uh on camtasia. that's our only sound record? mm. mm-hmm. how good is it? yeah. have to really question. mm-hmm. and then then they can do sound analysis on that. oh okay. right. so we there's gonna be a way to, sooner or later, to align the eye track, camtasia one, camtasia two with two sound channels. right. mm-hmm. ah, the bleep we'll find. mm. right. right. right. they uh they also tend to have a funny funny shape, beeps. so mm-hmm. mm-hmm. yeah, is there an end signal? when you decide it's all over, does it ping you back and right. okay. so when you've when you've pressed we're finished, it pings back at you? okay. it's just that all kinds of crazy things happen when you're running things, and so up saving a percentage of a trial is sometimes a good i you know, being able to do that is sometimes a good idea. okay. can w yeah, can we do can we do something better than that? like having yeah. yeah, i mean it's it's crazy. we're in an anechoic room which we specially, yeah, built an anechoic. but, you know, sound room which we specially built for this. we're d in good circumstances. we shouldn't screw it up more than we have to. is there anything we can do to improve this? no. no, no. do you have a powered microphone or something. right. that the line is stereo, the input is mono. right? is that what you said? right. is ah. that's somewhere in the sound card. yep. its own track, its own video. you have to align the videos anyway, right? i well i'm not the technical person who would do it. but i know who to ask. mm-hmm. mm-hmm. but it's the same as mm-hmm. says robin thinking about cutting and splicing, yeah. yeah, okay. mm-hmm. mm-hmm. yeah, i wanna see several of them. i wanna see i wanna see one of them um look really nice before we start running subjects. can we do that? yeah. yes, that's right. i just wanna know it works the way you expect it to work. this is not a a gesture of mistrust. this is just experience that um if anything can screw up it will. i i'm trying to choose my language carefully because we're being recorded. but you'll hear more choice language at the point when we've all done a lot of work and and then we discover we can't use the session because of some thing we didn't think about. right. um mm-hmm. mm-hmm. mm-hmm. right. and then then we combine yeah. it's probably worth mentioning this to the to the guys in the garage in toronto, right. to say mm-hmm. mm-hmm. mm-hmm. mm-hmm. uh-huh. right. i think that's a if the documentation said it w could record in stereo then i think we should talk to them about how they've done this. is you're not sure from the documentation what it says it can do? mm-hmm. right. okay. okay. mm-hmm. yeah. right. right. okay. right. right. right. okay, so when you i mean uh given that there are these events recorded, we can use any of them as the beginning of any of them as a start point, for example, right. um there are also motions being recorded of objects. right. mm-hmm. right. mm-hmm. okay.. right. yeah. so i'm right. uh that that that's great. i i'd before we break up for lunch i just wanna make sure that tha that i know how long it's gonna be before we're in run mode, okay. so the sound thing the sound thing is stands in our way, we need to be recording sound online. okay. so that's a thing that has to be solved. the shape thing is solved. mm-hmm. we think. we believe. right. so that's that that that should be done this week. um in fact like tomorrow for example. um the shape all the shape problems are solved. generating shapes, no problem. um scoring shape overlap, no problem. nothing is problem there. there are no visual display problems. mm-hmm. yeah, they had their they had their inspection last week. um j_p_ staggered away from it and ah. mm-hmm. okay. s um i haven't i haven't had any discussions with him since. well, he's ph he's physically here. if we want to pay him for some more time we can do that. would that be a just better use of our time in get yeah. right. but m he he he is around and i believe. and if if the if i if it's a right. but if um if everybody has a lot to do and, you know, joe could give it a couple of hours, which i is what it might take just to fix it, then let's do it because starting run-time is now getting to be fairly urgent. mm-hmm. mm-hmm. right. right. but we can't we can't make joe do this ec alright, so there's uh some trade-off between availability and speed from start to finish, given that this is somebody else's code. so you know. right, so we're we're b we're building models. right. we're we um we have the design somewhere. mm. hmm. well mm-hmm. okay. yeah. i think so. 'cause um i have to check back with with j_p_ fairly soon. okay, he wanted to kn um the eighteen the next eighteen month plan, great. deliverables, great. progress with the experiment, well that's what we're doing now. okay. so what do we think, if you have a fairly hectic week, are we looking for subjects next week? okay. ads go up. yeah, i do. i do. but i think ad should probably go up this week. we want people for n for next week. is that okay? is anybody now terrified at the thought that we're live next week? there are people coming in here one after another. or p two two after two, more likely. yeah. yeah. okay, is the is this is this generalised is this generalised anxiety, robin? or do you have a specific thing that okay. so aside from the usual angst which we all suffer when we go live. so we w we wanna do some piloting at the end of the week? right. okay. right. s right. she's using but she's actually relaxed that somewhat. yeah. mm-hmm. mm-hmm. ostensibly booked time, which isn't okay. we've but we have we have a solid booking for all the mornings anyway. right? and l except by permission of us, alright. we own it. um so we can change that. i mean they everybody acknowledged the the other week that we that we had priority. oh yeah. yeah, yeah, yeah. oh yeah, yeah. oh yeah, yeah. don't worry. um there's there's a booking system, right. so it's public what's booked and what isn't. okay. no. alright, maybe w should get on there and book mornings as far as the eye can see. alright. uh-huh. yeah, just a well we think we spoke to all the people who who used those facilities the other day. but we could be wrong. so huh. right. um well the two key holders are here. oh i see. from caroline? or the general office? the general office. i see. but no, they need a they need an account on this machine to actually to use it. they need account on these machines so that they could book. they couldn't actually log in. mm-hmm. okay. we're also working on a way of making sure that the matin that the machines return to zero state when they're when you come off them. because the it's the people have been leaving var um well, people have been leaving various bits of who knows what around on them, right, which which we think is what's critical. okay. um piloting piloting piloting. you have we have to build the things. we have to try the machi th things. we have to check them with marloes and j_p_ that they like the representation, the variables, right. how about uh you have any time on friday? i get a email back. maybe you and i should be the pilot subjects. first pilot subjects, the ones who um know which questions we wanna ask. and then we should get another pair who are naive to the whole thing. okay. this is generalised floating anxiety. no no. it's it's it's wisdom. but yeah. well um because actually we can i mean uh, you know, if we make comments, they feed back in a lo into the development.
uh five hundred hertz though. mm-hmm. yeah. uh m m i uh i yeah but the p sort of start and end times will give you back to that output. a as a and then you just measure it against, you know, the c the c yeah, the cumulative total time record or something. so mm-hmm. b uh uh m yeah, so i'll i'll lag in some of it during the i suppose there's the the saccadic movement itself, for example. th th th yeah, the it should still come out that the little sketch i asked this p for for last week about n_x_t_ and whether it would have that sort of tiered effect so you could see the overlap of where one person is looking compared to the other and their mouse movements and things. that that should ra uh address all that. mm-hmm. but but because it's also in the i based on the the time course of the procedure you'll be able to basically get the scan path of the pattern of events from that as well. yeah, yeah. so i did have it somewhere. i didn't have it r uh haven't brought it. trying to remember it. mm-hmm. the uh it m it m uh but uh br at that point they're all of it lumped all the individual fixations as long as it doesn't move off that triangle together as a total sort of gaze gaze time on that. yep. yeah. that that's a target within the target region. uh m uh-huh. m yes, somewhere. mm-hmm. it it sh yeah, it i mean uh as long as we're dif r yeah, it there shouldn't be anything missing. that should be alright... yeah. yep. m m yeah. yeah, yeah, yeah. mm-hmm. yes. so we yeah. so we if we have an an event, yeah, that that yeah, the second line then for the second before it. and then we can just take that chunk out and do something with it. that should i i right. yeah. mm-hmm. yeah. yeah. uh well, if it's just based on uh like a a stable fixation for so long or or something and crossing into that region. yeah. yep. mm-hmm. yep. mm-hmm. mm-hmm, yeah. to mm-hmm. don't know. mm-hmm. more. mm-hmm. mm-hmm. well he's really interested in mm-hmm. so which one does mm-hmm. mm-hmm. that's what i have understood it to be. but well i don't know. but w uh mm-hmm mm-hmm. yes, uh-huh, yeah. it's mm-hmm. mm-hmm. you can we can announce now. mm-hmm. mm-hmm. well uh but y y y you mean to the tags of the data w within it. yeah. so so things like fixation, the number of fixations a and bi um yeah, with some some measure of the so we could work out the number of fixations that made and the average fixation duration as well. because having st long steady fixations can be informative. um if if they're holding their if there's less dancing around, the um the cognitive focus tends to be in one sort of part. so uh there is a difference between if they even though they're still looking at the same part, if they're looking around it uh rather than just holding their gaze steady or um and longer on it. uh yeah. it, yeah, it's it's certainly it's it's worth mm-hmm. uh no, i wouldn't want to throw out put the actual location mm-hmm. mm-hmm. i mean presumably uh if well yes, but that probably isn't going to be easy to get out because you'd then have to break up uh the parts somehow. yep. mm-hmm. uh it it yes, it can do, but it's also looking at it within their their own behaviour to see, yeah. uh th w i i would say just the number of fixations. i mean it could just be yeah, the number of different yeah. yeah. mm-hmm. yep. exactly. so mm-hmm. i mean to it yeah. uh if if we've got everything, then i suppose it's you can always yes, it's you're not throwing anything away then. or right. mm-hmm. uh but uh uh number uh well the uh duration time as well somehow. whether it's the average one or of the fixation. well the the average should be alright uh to work with. the the uh well, if you've got the number of fixations in the average time, you can then just generate it. yeah, yeah. mm-hmm. uh again, uh that that should be you should be able to derive that presumably from right. uh that it can vary a bit depending on the calibration. but if we're building in a sort of error margin um it it will be based on pixels around. but there'll also be a minimum one. 'cause i'm trying to think that it's probably the small the actual mouse icon is so small, it'll need a slightly larger uh just because if what you have i is a sort of larger error or of b error margin around it. uh no. the o the other person's gaze position as well. mm-hmm. yep. trea treated the same as as the mouse say. yep. mm-hmm. yes, yep. yes. so if there uh if mm-hmm. yes. but not looking at their individual and pr fact, they probably will avoid looking directly. because if they're looking directly at it, it's obscuring the the part. mm-hmm. yeah, mm-hmm. the mm-hmm. mm-hmm. the m the mouse, the gaze and the part are all layered. mm-hmm. mm-hmm. mm-hmm. mm-hmm. uh uh if when they get moved together. mm-hmm. it mm-hmm. mm-hmm. two objects close together, your eye gaze can actually be looking at the left edge of one and the right edge of the other. and they're sor therefore looking at two objects at once. saying they need some new pens. new pens. white-board pens. mm-hmm. uh unle uh but it uh unless we just define it as there's only they're they are exclusive. and which ever area m has the greatest overlap is what they're actually looking at. well it w if if you've got your sort of eye position, and it's it's unlikely to be exactly fifty percent in one object and fifty percent in the other. uh well i uh uh put these things on. yeah. uh uh what i'm i'm thinking is if you've got say one object there and right. you know, so this is thank you. uh part one and part two. and you've got they're sort of they're looking there. then that overlap means they're looking at the two pieces simultaneously. but yeah, uh just if this is there's more of it uh yeah, i yes, uh that's w uh that's that's a decision we'll uh uh uh i'm saying is if they're looking if most of what their overlap is here then we stick with that one. uh that's th we no, that because um the gaze position will be a sort of fuzzy area. it won't just be a pixel. it'll it'll be an actual like circle and area. yeah. so i i it it that's that's going to be w uh it's it's not just a single point. it's it's a it's a sort of lump target. and so there'll be a bit of a a sort uh some sort of overlap of two objects. or b yeah, they could just be oscillating mm-hmm. mm-hmm. uh i mean if if they are oscillating though, then that's presumably going to st change the weight. so you are actually going to see them flipping between uh when you decide they're looking there mm-hmm, if they're really close, yeah. mm-hmm. h yes. hmm. the yeah. mm-hmm. mm-hmm. uh i it's also going to be a problem uh because you're going to have one part or a construct forming in the middle of a fixation. so it's not gonna be quite as clear if you can't can't chop it off. uh-huh. and then it yes. and it becomes construct or assembly whatever two. no. you can build sub sub-assemblies and then link the the part really, yeah. i so each wai w i th uh which constituent parts. construct. you'll be looking at the construct. 'cause that's the way it's dis defined. looking at areas within it. hmm. uh w they can't replace uh the new parts only appear when the previous one's broken. yes. they ca they can appear without them. you c uh with same shape but not the same shape and colour. uh same eye. yeah. yep. well that's well that's that's what they're at the moment. uh yes. so that's the way it works at the moment. uh i just assume that's how ni nijmegen had set it all up. th that's that's back to uh tim's day. they are individual uh you have different colours for the yep. unique, yeah. yes. the tam tamgrams are much easier when you can see mm-hmm. yep. it is just a construction task rather than a puzzle. yep. mm-hmm. yeah. uh yes. it at the moment there are d uh there are two i think two small ones and two large triangles. they're actually the same physical size and shape. at the moment they're in different colours. that also means in the p new parts list they're there for, you know, two v large triangles and two small one small ones, say. whereas in in the revised edition if they were all just black there'd only be one uh mold in the new parts. as far as i know it's hard-wired. it just appears so. mm-hmm. the polygon one, polygon two, whatever it might be. mm mm-hmm. yep. hmm. yep, same same pieces. mm-hmm. no, so they they can have different uh nuts there. w well nuts that are different colours. but same part in different colours, yeah. no, what i mean there's more than they're multiple pieces that look the same. mm-hmm. mm-hmm. mm-hmm. yes. mm-hmm. mm-hmm. and the extra parts don't appear. so you can't collect them. yeah. there there are a couple of them that it's like greyed out. they really very faint. so you see the mold is there. but they don't come filled uh until yes. yes. i i it appears in the new p uh like uh suddenly the th th the new part lights up sort of thing and it's there. yes. they have to bring it into play. no. nope. that yeah. that that is one think unlike the say the baufix or anything. we i assume the the baufix. the there aren't any extra parts. and at the moment the software doesn't a allow for that. yes. replacement, but no superfluous so you can't have a a standard stock with extra parts that it'll never use. mm-hmm. mm-hmm. yeah. mm-hmm. yeah. mm-hmm. intentional um in the sense that they break deliberately when they bring them into the new parts. but they c you know, it's like the trash can idea that they bring a you have to hope that there's language and one of them says something. you c mm-hmm. uh there's no there's there's no way you could tell that just from the the raw movements or or something. mm yep. yeah. it i although what i'm trying to remember is if the people deliberately break things by moving two pieces together. they they don't both break. they both they both mm-hmm. so the i intentional thing is when they actually both click on the same object and it breaks. no, they could just make a mistake or screw up, yeah. y yeah. but that's bringing in the the language thing again. mm-hmm. mm-hmm. oh uh yes. at the the percentage score. yeah. so our yes, rather than the number of penalties or or something. no, the the score w uh is fine. uh ye that's that's the way it's worked out. but uh uh the problem was um to do with the m the p they had a relative and absolute piece and uh it's all to s to the symmetry of that. so as long as it's defined, fine. yes. it wasn't it wasn't a bug. it it it was a uh well. uh yes, it was something that had to be defined and the uh dutch lot didn't. so that was it was actually their their fault. but um it's not clear enough in the documentation. yeah. yeah. but i it it is quite fundamental and uh causes quite immediate problems if you don't know about it. yep, exactly. yeah. or oh we're well we yeah. we should should go back to the beginning. the um camtasia was tested last week and initially we were a bit worried because uh in the old version it seemed to interfere with it. but uh when you when craig re-compiled it and did his new version it started wor wor it seems to work fine. um nothing we can tell. no uh mm-hmm. no. yes. there will now have to be two camtasia records because uh e each person actually sees a different screen because of the gaze feedback. they don't see their own gaze to the other person. so there'll need to be two separate camtasia videos generated. hopefully we won't. you mean officially? or uh yeah, i hadn't thought about the i was assuming we'd just get one and one licence both of us. suppose technically we should have two because it'll be two machines. i suspect that it will. it'll be per machine i would think. hmm. i i'll have a uh yeah, i'll have a l a look at the actual camtasia licence. um the other thing we're we it 'cause it's now twice twice the size of a uh mm. hmm. mm-hmm. mm-hmm. mm-hmm. well the other problem is uh camtasia has to be manually launched on both machines separately. yeah. uh during the task there is a flash and a bleep. oh i mean not during the task. uh before. for each task. yes. yes. uh camtasia y yeah. but no, they're they're on two s the two separate machines and the you you start and end them separately. the they they're not talking to each other. they're just recording. you start it recording and it starts recording what's on one screen. and you start the other recording on the other machine. and they're they're totally separate. they don't know about the other one. mm-hmm. yep. yes. uh yeah. see how how long it took them actually. that's that's true. how long did it take them to calibrate. or yeah. how many t how many times before uh the validation worked or something. yeah, that's true. i uh well it at the moment the that's what i was assuming on on on doing that uh it's done first. mm-hmm. you go back and actually yes, they were crap. isn't that the answer? yeah. um yes. the other thing we were getting sorted out was the the microphones. 'cause only one of the uh camtasia videos will actually have the soundtrack. uh we're just getting we've got one cable and to the two mics. i suppose we can do it is it would it be worth splitting it? uh yeah. so the at at at the moment it's ins well, what we've finally just uh at twelve o'clock today looks like we've got it sussed um is to get one channel one microphone being the left channel and one being the right channel to merge into a stereo single file. uh unfortunately the on one machine. the display p_c_s. yeah, the camtasia v video. or m m multi-media thing. yeah. yes. it it's yep. it's camtasia that's recording it.
yeah. yeah. yeah. yeah. yeah. so so m so i assume that well once you've that sort of information, you well you got the g_d_f_ format. you then filter it to say, right, between time x_ and time y_ they're they're constructing that having triangle one to the construct. and then you just say in that time period, what percentage are they looking at triangle one. what percentage are they looking at the construct. does that sound does that sound reasonable? yep. yeah, right. right. yeah, all all the all events have a start time and an end time. so yeah. yeah. yeah. yeah.. okay. yeah 'cause i think that that's gonna co that's 'cause b the diagram we got there suggesting that they're only looking thing at time. so whether it's triangle or whatever else. but so what you're suggesting there is they can be looking at the triangle and maybe a mouse pointer and maybe an eye at the same time. okay, okay. yeah. yep. yeah, yeah. 'cause you get c 'cause you yep. yeah. yep. yep, yep. okay, yeah. so so yeah. so so it's just a matter of adding these, the two mouse pointers and the um two gazes as extra objects. um so yeah. as long as as long as they've got an i_d_ in there we can just say right at this p between these times they're looking at that object or they're looking at the mouse, they're looking at whatever. yep. yeah. pens. i confuse 'em. yeah. that would yeah. yeah. well thing is that with yeah.. yeah. thing thing is w_g_d_s_ formats is wor is working at the moment. it's actually got a separate track for each part. so yeah. well the well the the the it depen depends on the depends on what you build in. there's different parts there's different parts whether you're doing the tamgram or whether you're doing an airpa airplane or whatever. um but th but sa but thing is if if we if we got if we got tracks for each for each part we can we can easily analyse it down later on. yeah. yeah, well the yeah. yeah. well the the the the doesn't really list part in the in the g_d_f_. um so yeah. that that that's not a problem. there so that bas basically what i've got is well there there there's places where you got the i_d_ though. so you've the an i_d_ for a part, you got an i_d_ for a location on the screen. so it shows you the target, config the clock, whatever else. um and then we can easy add i_d_s for the two mouse points and the two gazes. um and from that and ba basically all all the all the tracks are doing is saying at this between this time there's a look at this o this object. yeah, th this i_d_. um so uh so it's effectively a track for each i_d_. the th yeah the but but well wha wha what happen what happens there is that the the two the the existing parts basically cease to exist and a new part with a new i_d_ starts existing at the point where they're joined. yep. yeah. right. yeah. oh. yeah. yeah, that that that that's what that's what that's the way he's working the moment. because it uh th it's it's generating a new i_d_ when you c when you create a new part. um yeah. um yeah. but there there's there's joint events. so if the if a joint event if if if it's there's joint event linked to linked to the item then you know it's become part of a construct. um of um yeah, the the the yeah. the con the con the constructs are already tagged with that. so that i'm act there's actually a s a separate file of the data format which says for each construct, which which two parts made it made that came together to make that construct. yeah. but you can still ta you can still track what parts went into it. so you can still find triangle one, whatever. yeah. yeah. but but that's easy n uh it's easy to do because the the co each construct has the i_d_s for the pa the things that construct it. yeah. yeah. well we'll d yeah well with the yeah d well thing is that we we still have the x_ wa the x_ wave traces from the ascii formats. so if if you want if you want to be able to say i'm looking at a square instead of i'm looking at the construct, that's it is possible to get that data out. um it's it's yeah. it's it's not doing it's not doing it in the gest analyzer at the moment. but i can easily add it to give that information if you want. yeah, if if you take it if you t if you crea if you create a new part, it uh it gets a new i_d_. so if you get if you drag a new part out of the parts bin uh yeah, i mean the we e yeah, i mean you know whi you know which way they match. so you can yeah, the yep. yeah. yeah. so yeah. yeah, so i think that anything's loading. there's there's then two triangle, isn't there? there's two identical triangles in the tamgram. um well yeah yeah. when you when you specify the molds in the in the in the p the file that c that generates the parts, like a list of parts, the molds are bas just taken out of the the file that generate that specifies the parts. so so ho however many part however many mo however many parts there are in the file, that's how many parts appear in the in the parts box. if you have five black triangles gonna be five five parts in the fi five black black triangles in the parts box. but what what what but what you can do well if in the in the initial configuration you can re-use a triangle. so if you so if you only want one black triangle, you just create one black triangle in the parts box and then re-use that pa that triangle five times in the configuration. yep. yep. well when the when the f when the final construct the the way the the way the the constructs are defined in the file, you've got like your p your parent construct and the parts that it's constructed out of. um and yeah, as i say, the yeah, yeah. so you got parent child relationship and i the child can be a part or it can be another construct. yeah, yeah. 'cause uh there's a joint action. the result the t what you need for a join action you need to yeah, a construct and a part, two parts, whate whatever you're taking together. and then the result of that is a construct. you've got time when that happens. you can see that construct appeared at that time. um and you can still track the children of that construct. yep. yeah. yeah, well by by the by the time by the time they're doing that they must have already broken something. so you'll so you'll know what they're replacing. so uh they do. if if if what if one if one person's trying to get a part to a part that isn't that that so the part that's just sitting on the screen that's not being touched. they both break. yeah. yeah. yeah. yeah. uh well yeah. 'cause yeah. c 'cause it was through the rotational part. yeah. yep. yeah. yeah, i mean i'm i've th i've yeah. it's it's in the documentation. but it's like two thirds of the way down a quite a long page. so yep. but um yeah. yeah. no. no the the the there's there's very small graphical bugs. but it's it's not it's not big thing. it's like couple of white pixels uh in the course of a in the course of a the course of a task. so it's there's distracting. no. yeah, but then the que the que the question is there a licence for camtasia where you just need one editing c thing and two recording things. 'cause yeah, the r the recording yeah, the recording thi pro program is just quite a it's quite a small program. they just gen it just generates the video and so i don't know don't know if it's worth having a look at the licensing for that just to see. yeah. yep.. mm. yeah. no, you got you yeah, you got exactly the same access to sound quality as you got from anythi anything else on the windows. so you can you decide whatever quality you want. so got a bit of uh yeah. because the the synchronization, the audio and vi the audio visual synchronisation comes at a specific point in the eye track file. no, it's yeah th it's i i sta stamped into it. so it's just after just after it prints the line starting experiment uh uh yeah. i'll i'm pretty sure it's just yeah. yep. uh well the well the matlab script uh bas just sa uh just says uh yeah, gi gi gives you the times of the audio beep in the s in the signal. so i just yeah. yeah. oh yeah. yeah. pretty confident. but you you've you've seen them. it it was it was yeah. yeah, i don't see him with ten he kilohertz. yeah. yeah, the the the there's a signal at the start and the end of every trial. so yep. yep. yes, it's a stereo jack. it's a stereo jack. but it's a mono but it's a mono uh microphone. mono mono recording on microphones. line in. uh sp going going through a line in. so it's a so it's a lit so it's quieter because it's not as though it's not powered. but it's still, think, yeah. we we still pick up a signal. yeah. yeah. well the the when they are they are the the they have batteries in them. but i there's not doesn't. but doesn't seem to be powered because the because the line in input's so low. the so the sound the sound the s well the yeah, the the yeah, the the the the jack that is that it's plugged into is stereo. but when you plug in when it's recording from microphone, it records in mono. and yeah. a new sound card is fixable. yeah. als think we we have a well i suppo i suppose it well one th one thing you do is uh re is record the sou speech signal separately for each for each person. but then you'd have to pull the two pull the two sounds together. so if uh so if i i if each machine recorded its own with a recorded the recorded like the the p th the uh the user on that one. yeah. yeah. oh they yeah. and then the so the yeah. so th yeah, it's easy. easy. if if nothing if nothing else you h uh if nothing else you can do it in a matlab script. you just write read read file one, read file two. and then you just yeah. yeah, but then the the the matlab the matlab script will tell you how l it will tell you how far apart they are. 'cause you can do you can just measure the drift between the two of them. 'cause you got a l you got a list of where the where the beeps are. and then you say right, this stream is like, i don't know, nought point two five seconds behind the other one. yeah. mm-hmm. yeah. so then they've both got the same sound card. so yeah. yeah. yeah. 'cause 'cause 'cause yes. yeah. so the the external version's got plugs that size and that that is stereo microphones. but yeah. the other one's plug's like the smaller size and that isn't stereo. so the colour the colour can do it. it's just that the connectors on the the connectors at the back of the computer can't. yeah. but as as far far as we can and find the the web site of the, yeah, the the creative labs web site and the review of it. um and they weren't entirely clear. but they both suggested that it is there is a mono that there there is a mono microphone. yeah. yeah, i'm yeah. so and basically out the output the g_d_f_ is just gonna be a whole series of events, you know, with start and end time. and the event's gonna have whatever all whatever the object uh is that's being looked at and things. um and then, yeah, and then it's a matter of we're gonna put whatever filters you need after that. so you can say right, i just want so you can say from the time where they picked up triangle one to the part time it became part of the assembly, find out how it's how m percentages of time they were looking at it or whatever. yep. so yeah. so you got mo yeah. there there's move events. there's look events. there's fixations and blinks now at the moment as well. um and, yeah, and oh yeah and see uh looks at looks at objects and looks whatever else. so um s yep. yep. yeah. yeah i will.. yep. yep. okay. fair enough. okay. well yeah. yeah. yeah. yep. yeah. so we'll we'll get we'll get the get the audio stuff tested, you know, single microphones. um yeah. get that tested next couple days and i assu i assume that's not something you need me for t in terms of that.. you don't you don't need me involved in the pilot, do you. so well unle unless unless it's a bug report, yeah. i'll w yeah w i'll i'll i'll b i'll be around. but yeah, i'll make sure. but ho hopefully it will run smoothly and yeah, i can relax. so
